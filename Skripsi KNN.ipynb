{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________\n",
      " Perimeter: 1347.63\n",
      "_________________________________________\n",
      "_________________________________________\n",
      " Infected area: 1941.50\n",
      "_________________________________________\n",
      "_________________________________________\n",
      " Total area: 43036.00\n",
      "_________________________________________\n",
      "_________________________________________\n",
      " Percentage of infection region: 4.51\n",
      "_________________________________________\n",
      "Appending to C:/Users/USER/Desktop/skripsi/data_uji.csv...\n",
      "\n",
      "File C:/Users/USER/Desktop/skripsi/data_uji.csv updated!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np           \n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "text = str('grapeleaves_2.jpg')\n",
    "img = cv2.imread(text)\n",
    "original = img.copy()\n",
    "neworiginal = img.copy() \n",
    "cv2.imshow('original',img)\n",
    "\n",
    "#Guassian blur\n",
    "blur1 = cv2.GaussianBlur(img,(3,3),1)\n",
    "cv2.imshow('gaussian blur',blur1)\n",
    "\n",
    "#mean-shift algo\n",
    "newimg = np.zeros((img.shape[0], img.shape[1],3),np.uint8)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER , 10 ,1.0)\n",
    "\n",
    "img = cv2.pyrMeanShiftFiltering(blur1, 20, 30, newimg, 0, criteria)\n",
    "cv2.imshow('means shift image',img)\n",
    "\n",
    "#Guassian blur\n",
    "blur = cv2.GaussianBlur(img,(11,11),1)\n",
    "\n",
    "#Canny-edge detection\n",
    "canny = cv2.Canny(blur, 160, 290)\n",
    "canny = cv2.cvtColor(canny,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "bordered = cv2.cvtColor(canny,cv2.COLOR_BGR2GRAY)\n",
    "_,contours,hierarchy = cv2.findContours(bordered, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "maxC = 0\n",
    "for x in range(len(contours)):\n",
    "    if len(contours[x]) > maxC:\n",
    "        maxC = len(contours[x])\n",
    "        maxid = x\n",
    "\n",
    "perimeter = cv2.arcLength(contours[maxid],True)\n",
    "#print perimeter\n",
    "Tarea = cv2.contourArea(contours[maxid])\n",
    "cv2.drawContours(neworiginal,contours[maxid],-1,(0,0,255))\n",
    "cv2.imshow('Contour',neworiginal)\n",
    "\n",
    "height, width, _ = canny.shape\n",
    "min_x, min_y = width, height\n",
    "max_x = max_y = 0\n",
    "frame = canny.copy()\n",
    "\n",
    "for contour, hier in zip(contours, hierarchy):\n",
    "    (x,y,w,h) = cv2.boundingRect(contours[maxid])\n",
    "    min_x, max_x = min(x, min_x), max(x+w, max_x)\n",
    "    min_y, max_y = min(y, min_y), max(y+h, max_y)\n",
    "    if w > 80 and h > 80:\n",
    "        #cv2.rectangle(frame, (x,y), (x+w,y+h), (255, 0, 0), 2)   #we do not draw the rectangle as it interferes with contour later on\n",
    "        roi = img[y:y+h , x:x+w]\n",
    "        originalroi = original[y:y+h , x:x+w]\n",
    "\n",
    "if (max_x - min_x > 0 and max_y - min_y > 0):\n",
    "    roi = img[min_y:max_y , min_x:max_x]\n",
    "    originalroi = original[min_y:max_y , min_x:max_x]\n",
    "    #cv2.rectangle(frame, (min_x, min_y), (max_x, max_y), (255, 0, 0), 2)   #we do not draw the rectangle as it interferes with contour\n",
    "\n",
    "cv2.imshow('ROI', frame)\n",
    "cv2.imshow('rectangle ROI', roi)\n",
    "img = roi\n",
    "\n",
    "#Changing colour-space\n",
    "imghls = cv2.cvtColor(roi, cv2.COLOR_BGR2HLS)\n",
    "cv2.imshow('HSI', imghls)\n",
    "imghls[np.where((imghls==[30,200,2]).all(axis=2))] = [0,200,0]\n",
    "\n",
    "huehls = imghls[:,:,0]\n",
    "cv2.imshow('img_hue hls',huehls)\n",
    "huehls[np.where(huehls==[0])] = [35]\n",
    "\n",
    "ret, thresh = cv2.threshold(huehls,28,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('thresh', thresh)\n",
    "\n",
    "mask = cv2.bitwise_and(originalroi,originalroi,mask = thresh)\n",
    "cv2.imshow('masked out img',mask)\n",
    "\n",
    "#Finding contours for all infected regions\n",
    "_,contours,heirarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "Infarea = 0\n",
    "for x in range(len(contours)):\n",
    "    cv2.drawContours(originalroi,contours[x],-1,(0,0,255))\n",
    "    cv2.imshow('Contour masked',originalroi)\n",
    "    \n",
    "#Calculating area of infected region\n",
    "    Infarea += cv2.contourArea(contours[x])\n",
    "\n",
    "if Infarea > Tarea:\n",
    "    Tarea = img.shape[0]*img.shape[1]\n",
    "\n",
    "print ('_________________________________________\\n Perimeter: %.2f' %(perimeter) \n",
    "       + '\\n_________________________________________')\n",
    "print ('_________________________________________\\n Infected area: %.2f' %(Infarea) \n",
    "       + '\\n_________________________________________')\n",
    "\n",
    "print ('_________________________________________\\n Total area: %.2f' %(Tarea) \n",
    "       + '\\n_________________________________________')\n",
    "\n",
    "#Finding the percentage of infection in the leaf\n",
    "\n",
    "try:\n",
    "    per = 100 * Infarea/Tarea\n",
    "except ZeroDivisionError:\n",
    "    per = 0\n",
    "\n",
    "print ('_________________________________________\\n Percentage of infection region: %.2f' %(per) \n",
    "       + '\\n_________________________________________')\n",
    "\n",
    "#import csv file library \n",
    "import csv\n",
    "\n",
    "directory = r'C:/Users/USER/Desktop/skripsi'\n",
    "filename = directory +'/data_uji.csv' \n",
    "imgid = \"/\".join(text.split('/')[-2:])\n",
    "\n",
    "fieldnames = ['fold num', 'imgid', 'feature1', 'feature2', 'feature3']\n",
    "print ('Appending to ' + str(filename)+ '...')\n",
    "         \n",
    "try:\n",
    "        log = pd.read_csv(filename)\n",
    "        logfn = pd.to_numeric(log.tail(1)['fold num'], errors='coerce')\n",
    "        foldnum = (logfn+1)%10\n",
    "        L = [str(foldnum), imgid, str(Tarea), str(Infarea), str(perimeter)]\n",
    "        my_df = pd.DataFrame([L])\n",
    "        my_df.to_csv(filename, mode='a', index=False, header=False)\n",
    "        print ('\\nFile ' + str(filename)+ ' updated!' )\n",
    "                \n",
    "\n",
    "except IOError:\n",
    "        if directory not in os.listdir():\n",
    "            os.system('mkdir ' + directory)\n",
    "\n",
    "        foldnum = 0\n",
    "        L = [str(foldnum), imgid, str(Tarea), str(Infarea), str(perimeter)]\n",
    "\n",
    "        my_df = pd.DataFrame([fieldnames, L])\n",
    "        my_df.to_csv(filename, index=False, header=False)\n",
    "        print ('\\nFile ' + str(filename)+ ' updated!' )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training dataset:-\n",
      "\n",
      "     feature1  feature2     feature3\n",
      "0     39425.5       0.0   933.761535\n",
      "1     39270.5       0.0   842.281306\n",
      "2     36300.0       0.0   988.004176\n",
      "3       213.5       0.0  1592.403232\n",
      "4       196.0       0.0  1644.846884\n",
      "5       181.0       0.0  1549.876321\n",
      "6     29747.5       0.0   788.080296\n",
      "7     31967.5       0.0   964.589962\n",
      "8     36382.5       0.0  1032.874233\n",
      "9       234.0       0.0  1762.469248\n",
      "10    31259.5       0.0   881.477264\n",
      "11      121.5       0.0   897.075244\n",
      "12    33855.5       0.0   964.648837\n",
      "13    37829.5       0.0   889.820410\n",
      "14    34151.0       0.0   845.033613\n",
      "15      204.5       0.0  1819.314920\n",
      "16    36228.0       0.0   855.920916\n",
      "17      215.5       0.0  1752.084472\n",
      "18    37224.5       0.0  1022.388952\n",
      "19      219.0       0.0  1693.900706\n",
      "20      255.5       0.0  1853.765711\n",
      "21    36942.0       0.0   964.430582\n",
      "22      208.0       0.0  1838.871269\n",
      "23      163.5       0.0  1495.751431\n",
      "24    31229.0       0.0   913.376759\n",
      "25    35263.5       0.0  1045.158504\n",
      "26      190.0       0.0  1623.675311\n",
      "27      253.0       0.0  2054.576893\n",
      "28      283.0       0.0  2130.802289\n",
      "29      255.5       0.0  1893.623576\n",
      "..        ...       ...          ...\n",
      "300     231.0       0.0  1711.439810\n",
      "301   31187.0       0.0   828.264062\n",
      "302     200.5       0.0  1510.947389\n",
      "303   32774.0       0.0   818.607207\n",
      "304   32575.5       0.0   911.134119\n",
      "305     212.0       0.0  1780.670258\n",
      "306   38660.5       0.0   904.364567\n",
      "307     270.0       0.0  1852.635768\n",
      "308     268.5       0.0  1929.932232\n",
      "309     288.0       0.0  2124.317008\n",
      "310   31179.5       0.0   870.790973\n",
      "311     220.5       0.0  1860.711888\n",
      "312     255.5       0.0  1833.765711\n",
      "313     187.0       0.0  1743.616436\n",
      "314   30059.0       0.0  1108.798113\n",
      "315   30947.0       0.0   860.548332\n",
      "316     245.5       0.0  1880.250992\n",
      "317     149.0       0.0  1093.543280\n",
      "318     246.0       0.0  1994.434758\n",
      "319   36902.5       0.0   831.050858\n",
      "320     193.0       0.0  1818.788008\n",
      "321   33532.0       0.0   875.577770\n",
      "322   32382.0       0.0   891.719905\n",
      "323   38398.0       0.0   941.862040\n",
      "324   34772.0       0.0   853.033613\n",
      "325     216.5       0.0  1801.599191\n",
      "326   36354.0       0.0   871.293499\n",
      "327     254.5       0.0  1640.368743\n",
      "328   33080.0       0.0   853.636645\n",
      "329   28667.0       0.0   768.121926\n",
      "\n",
      "[330 rows x 3 columns]\n",
      "\n",
      "Test dataset:-\n",
      "\n",
      "     feature1  feature2    feature3\n",
      "138   43036.0    1941.5  1347.63368\n",
      "\n",
      "Prediksi : \n",
      "Daun Berpenyakit\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [165, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-846eb887f724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [165, 1]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# reading csv file and extracting class column to y.\n",
    "data = pd.read_csv(\"dataset_grapeleaves.csv\")\n",
    "\n",
    "# extracting two features\n",
    "X = data.drop(['imgid','fold num'], axis=1)\n",
    "y = X['label']\n",
    "X = X.drop('label', axis=1)\n",
    "print(\"\\nTraining dataset:-\\n\")\n",
    "print(X)\n",
    "\n",
    "log = pd.read_csv(\"data_uji.csv\")\n",
    "\n",
    "log = log.tail(1)\n",
    "X_ul = log.drop(['imgid','fold num'], axis=1)\n",
    "\n",
    "print(\"\\nTest dataset:-\\n\")\n",
    "print(X_ul)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X,y)\n",
    "pred = knn.predict(X_ul)\n",
    "print(\"\\nPrediksi : \")\n",
    "if (pred == 0):\n",
    "    print(\"Daun Sehat\")\n",
    "else:\n",
    "    print(\"Daun Berpenyakit\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, pred))\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  7]\n",
      " [34 57]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7515151515151515"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=0)\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.transform(X_test)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [165, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-207ab38c172b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_pred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_ul\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Ana3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [165, 1]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred1 = knn.predict(X_ul)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
